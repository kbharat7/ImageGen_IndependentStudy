{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import os\n",
        "import numpy as np\n",
        "from torchvision.datasets.folder import ImageFolder\n",
        "from torchvision.datasets.folder import default_loader\n",
        "import timm\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713559604215
        },
        "id": "Y8ACti5mkYgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up data transformations and custom dataset class\n",
        "def get_transforms():\n",
        "    return transforms.Compose([\n",
        "\n",
        "        transforms.Normalize(mean=[0.4965, 0.4965, 0.4964],\n",
        "                             std=[0.2105, 0.2105, 0.2106])\n",
        "    ])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713559607015
        },
        "id": "mwA6wZDokYgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(datasets.ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        path, target = self.samples[index]\n",
        "        sample = self.loader(path)\n",
        "        sample = sample.convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, target"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713559608956
        },
        "id": "hz6aaCjkkYgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and DataLoader setup\n",
        "def get_dataloaders(train_dir, val_dir, batch_size):\n",
        "    train_transforms = get_transforms()\n",
        "    val_transforms = get_transforms()\n",
        "\n",
        "    train_dataset = CustomDataset(root=train_dir, transform=train_transforms)\n",
        "    val_dataset = CustomDataset(root=val_dir, transform=val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, train_dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713559611009
        },
        "id": "al4c65h2kYgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_model(model, device, num_classes):\n",
        "    model = timm.create_model(model, pretrained=True, num_classes=num_classes)\n",
        "\n",
        "    # No need to modify the final layer manually as in torchvision,\n",
        "    # timm handles this with the num_classes parameter in create_model\n",
        "    model = model.to(device)\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713559612779
        },
        "id": "Yj9TgHfSkYgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_weights(train_dataset):\n",
        "    # Count the number of occurrences of each class\n",
        "    class_counts = torch.zeros((len(train_dataset.classes)), dtype=torch.float)\n",
        "    for _, label in train_dataset:\n",
        "        class_counts[label] += 1\n",
        "\n",
        "    # Compute class weights (inverse frequency or another method)\n",
        "    class_weights = 1. / class_counts\n",
        "    class_weights = (class_weights / class_weights.sum()) * len(train_dataset.classes)\n",
        "    return class_weights"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713559615114
        },
        "id": "2rhHUBCbkYgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation function\n",
        "def validate_model(model, val_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = val_loss / len(val_loader.dataset)\n",
        "    epoch_acc = val_corrects.double() / len(val_loader.dataset)\n",
        "    return epoch_loss, epoch_acc"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713559617812
        },
        "id": "8PL9zRtSkYgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with mixed precision\n",
        "def train_model(model_name, model, train_loader, device, epochs, class_weights):\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.01)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        val_loss, val_acc = validate_model(model, val_loader, device)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # Save the best model based on validation loss\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "    # Save the best model found during training\n",
        "    if best_model_state:\n",
        "        torch.save(best_model_state, f'{model_name}_final.pth')\n",
        "        print(\"Saved the best model based on validation loss.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713559622610
        },
        "id": "DiznYG-KkYgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {torch.cuda.get_device_name(0)}')\n",
        "\n",
        "val_dir = 'valid_data/'\n",
        "train_dir = 'data/cleaned_images/cleaned_combined_images/'\n",
        "batch_size = 16\n",
        "num_classes = 3\n",
        "epochs = 30\n",
        "\n",
        "train_loader, val_loader, train_dataset = get_dataloaders(train_dir, val_dir, batch_size)\n",
        "\n",
        "class_weights = calculate_class_weights(train_dataset)\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "# model_resnet = setup_model('resnet50', device, num_classes)\n",
        "model_efficientnet = setup_model('inception_resnet_v2', device, num_classes)\n",
        "# train_model('resnet50', model_resnet, train_loader, device, epochs, class_weights)\n",
        "train_model('inception_resnet_v2', model_efficientnet, train_loader, device, epochs, class_weights)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using device: NVIDIA A100 80GB PCIe\nEpoch 1/30, Train Loss: 0.2670, Val Loss: 0.7008, Val Acc: 0.6400\nEpoch 2/30, Train Loss: 0.1278, Val Loss: 0.7970, Val Acc: 0.6700\nEpoch 3/30, Train Loss: 0.0957, Val Loss: 0.6400, Val Acc: 0.7050\nEpoch 4/30, Train Loss: 0.0765, Val Loss: 0.9688, Val Acc: 0.6700\nEpoch 5/30, Train Loss: 0.0570, Val Loss: 0.8228, Val Acc: 0.7000\nEpoch 6/30, Train Loss: 0.0363, Val Loss: 0.9099, Val Acc: 0.6900\nEpoch 7/30, Train Loss: 0.0299, Val Loss: 0.7746, Val Acc: 0.7250\nEpoch 8/30, Train Loss: 0.0268, Val Loss: 1.1664, Val Acc: 0.7100\nEpoch 9/30, Train Loss: 0.0210, Val Loss: 0.9911, Val Acc: 0.7700\nEpoch 10/30, Train Loss: 0.0185, Val Loss: 1.1532, Val Acc: 0.7300\nEpoch 11/30, Train Loss: 0.0161, Val Loss: 1.0944, Val Acc: 0.6950\nEpoch 12/30, Train Loss: 0.0175, Val Loss: 1.2109, Val Acc: 0.6850\nEpoch 13/30, Train Loss: 0.0211, Val Loss: 1.0381, Val Acc: 0.7000\nEpoch 14/30, Train Loss: 0.0144, Val Loss: 0.9846, Val Acc: 0.7200\nEpoch 15/30, Train Loss: 0.0149, Val Loss: 1.0914, Val Acc: 0.7100\nEpoch 16/30, Train Loss: 0.0078, Val Loss: 1.1489, Val Acc: 0.6950\nEpoch 17/30, Train Loss: 0.0098, Val Loss: 1.1354, Val Acc: 0.7000\nEpoch 18/30, Train Loss: 0.0078, Val Loss: 1.0528, Val Acc: 0.6900\nEpoch 19/30, Train Loss: 0.0092, Val Loss: 1.0670, Val Acc: 0.7150\nEpoch 20/30, Train Loss: 0.0069, Val Loss: 1.0627, Val Acc: 0.7150\nEpoch 21/30, Train Loss: 0.0064, Val Loss: 1.1390, Val Acc: 0.7150\nEpoch 22/30, Train Loss: 0.0052, Val Loss: 1.0986, Val Acc: 0.7100\nEpoch 23/30, Train Loss: 0.0050, Val Loss: 1.1492, Val Acc: 0.7150\nEpoch 24/30, Train Loss: 0.0046, Val Loss: 1.0945, Val Acc: 0.6950\nEpoch 25/30, Train Loss: 0.0051, Val Loss: 1.2180, Val Acc: 0.7000\nEpoch 26/30, Train Loss: 0.0047, Val Loss: 1.1091, Val Acc: 0.6900\nEpoch 27/30, Train Loss: 0.0058, Val Loss: 1.0673, Val Acc: 0.6950\nEpoch 28/30, Train Loss: 0.0041, Val Loss: 1.0154, Val Acc: 0.7050\nEpoch 29/30, Train Loss: 0.0045, Val Loss: 1.1505, Val Acc: 0.7050\nEpoch 30/30, Train Loss: 0.0043, Val Loss: 1.1897, Val Acc: 0.7000\nSaved the best model based on validation loss.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_12652/2429079452.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713563743794
        },
        "id": "8MYa-fVmkYgS",
        "outputId": "8d4c4e1a-e2f5-40cd-8e29-cfa22d79d0bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {torch.cuda.get_device_name(0)}')\n",
        "\n",
        "val_dir = 'valid_data/'\n",
        "train_dir = 'data/cleaned_images/cleaned_combined_images/'\n",
        "batch_size = 16\n",
        "num_classes = 3\n",
        "epochs = 30\n",
        "\n",
        "train_loader, val_loader, train_dataset = get_dataloaders(train_dir, val_dir, batch_size)\n",
        "\n",
        "class_weights = calculate_class_weights(train_dataset)\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "# model_resnet = setup_model('resnet50', device, num_classes)\n",
        "model_efficientnet = setup_model('nasnetalarge', device, num_classes)\n",
        "# train_model('resnet50', model_resnet, train_loader, device, epochs, class_weights)\n",
        "train_model('nasnetalarge', model_efficientnet, train_loader, device, epochs, class_weights)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using device: NVIDIA A100 80GB PCIe\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/356M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4165ec07e66c4191b1a28e03a284507c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_12652/2429079452.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/30, Train Loss: 0.2406, Val Loss: 0.6772, Val Acc: 0.6750\nEpoch 2/30, Train Loss: 0.1112, Val Loss: 0.6313, Val Acc: 0.7100\nEpoch 3/30, Train Loss: 0.0796, Val Loss: 0.6921, Val Acc: 0.7350\nEpoch 4/30, Train Loss: 0.0467, Val Loss: 0.7840, Val Acc: 0.7400\nEpoch 5/30, Train Loss: 0.0435, Val Loss: 0.7637, Val Acc: 0.6950\nEpoch 6/30, Train Loss: 0.0245, Val Loss: 0.8776, Val Acc: 0.7150\nEpoch 7/30, Train Loss: 0.0236, Val Loss: 0.8768, Val Acc: 0.7050\nEpoch 8/30, Train Loss: 0.0143, Val Loss: 0.9930, Val Acc: 0.7300\nEpoch 9/30, Train Loss: 0.0187, Val Loss: 1.0590, Val Acc: 0.7250\nEpoch 10/30, Train Loss: 0.0100, Val Loss: 1.4519, Val Acc: 0.7350\nEpoch 11/30, Train Loss: 0.0115, Val Loss: 1.4803, Val Acc: 0.6950\nEpoch 12/30, Train Loss: 0.0168, Val Loss: 1.0150, Val Acc: 0.7300\nEpoch 13/30, Train Loss: 0.0118, Val Loss: 1.3243, Val Acc: 0.7400\nEpoch 14/30, Train Loss: 0.0109, Val Loss: 1.4470, Val Acc: 0.6850\nEpoch 15/30, Train Loss: 0.0102, Val Loss: 1.6907, Val Acc: 0.7200\nEpoch 16/30, Train Loss: 0.0047, Val Loss: 1.4884, Val Acc: 0.7400\nEpoch 17/30, Train Loss: 0.0060, Val Loss: 1.5637, Val Acc: 0.7350\nEpoch 18/30, Train Loss: 0.0056, Val Loss: 1.3468, Val Acc: 0.7300\nEpoch 19/30, Train Loss: 0.0040, Val Loss: 1.5502, Val Acc: 0.7250\nEpoch 20/30, Train Loss: 0.0038, Val Loss: 1.4003, Val Acc: 0.7500\nEpoch 21/30, Train Loss: 0.0034, Val Loss: 1.5154, Val Acc: 0.7350\nEpoch 22/30, Train Loss: 0.0038, Val Loss: 1.5465, Val Acc: 0.7150\nEpoch 23/30, Train Loss: 0.0029, Val Loss: 1.6312, Val Acc: 0.7100\nEpoch 24/30, Train Loss: 0.0028, Val Loss: 1.5042, Val Acc: 0.7000\nEpoch 25/30, Train Loss: 0.0031, Val Loss: 1.5169, Val Acc: 0.7250\nEpoch 26/30, Train Loss: 0.0024, Val Loss: 1.5930, Val Acc: 0.7350\nEpoch 27/30, Train Loss: 0.0028, Val Loss: 1.5086, Val Acc: 0.7150\nEpoch 28/30, Train Loss: 0.0027, Val Loss: 1.6213, Val Acc: 0.7350\nEpoch 29/30, Train Loss: 0.0023, Val Loss: 1.5818, Val Acc: 0.7400\nEpoch 30/30, Train Loss: 0.0020, Val Loss: 1.6724, Val Acc: 0.7100\nSaved the best model based on validation loss.\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713570310067
        },
        "colab": {
          "referenced_widgets": [
            "4165ec07e66c4191b1a28e03a284507c"
          ]
        },
        "id": "q69vB1ZIkYgT",
        "outputId": "16416174-10ba-4fa3-bb80-2a7767881331"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "\n",
        "def load_model(model_name, checkpoint_path, num_classes):\n",
        "    # Load the model structure from timm\n",
        "    model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
        "    # Load the trained state dictionary\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    return model\n",
        "\n",
        "# Specify the path to your model checkpoints and number of classes\n",
        "nasnet_checkpoint = 'nasnetalarge_final.pth'\n",
        "inception_resnet_v2_checkpoint = 'inception_resnet_v2_final.pth'\n",
        "num_classes = 3\n",
        "\n",
        "# Load the models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "nasnet_model = load_model('nasnetalarge', nasnet_checkpoint, num_classes).to(device)\n",
        "inception_resnet_v2_model = load_model('inception_resnet_v2', inception_resnet_v2_checkpoint, num_classes).to(device)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713577080977
        },
        "id": "7_TdVXIAkYgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the transformation, adjust according to how your model was trained\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((600, 600)),\n",
        "    transforms.CenterCrop(500),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4965, 0.4965, 0.4964],\n",
        "                             std=[0.2105, 0.2105, 0.2106]),\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "test_dir = 'Test'\n",
        "test_dataset = ImageFolder(root=test_dir, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713577741513
        },
        "id": "hxAwmJ6GkYgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_images_with_filenames(model, device, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    filenames = []\n",
        "    with torch.no_grad():\n",
        "        for images, _ in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            # Capture filenames from the dataset\n",
        "            filenames.extend([dataloader.dataset.samples[i][0] for i in range(len(images))])\n",
        "\n",
        "    return filenames, predictions\n",
        "\n",
        "filenames_nasnet, predictions_nasnet = predict_images_with_filenames(nasnet_model, device, test_loader)\n",
        "filenames_inception, predictions_inception = predict_images_with_filenames(inception_resnet_v2_model, device, test_loader)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713577838501
        },
        "id": "rB4jxRBnkYgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_filenames_nasnet = [os.path.basename(f) for f in filenames_nasnet]\n",
        "base_filenames_inception = [os.path.basename(f) for f in filenames_inception]\n",
        "\n",
        "# Create DataFrame\n",
        "results_df_inception = pd.DataFrame({\n",
        "    'Filename': base_filenames_inception,\n",
        "    'Prediction': predictions_inception\n",
        "})\n",
        "\n",
        "results_df_nasnet = pd.DataFrame({\n",
        "    'Filename': base_filenames_nasnet,\n",
        "    'Prediction': predictions_nasnet\n",
        "})\n",
        "\n",
        "# Save to Excel\n",
        "path_inception = 'predicted_results_inception.csv'\n",
        "path_nasnet = 'predicted_results_nasnet.csv'\n",
        "results_df_inception.to_csv(path_inception, index=False, header=False)\n",
        "results_df_nasnet.to_csv(path_nasnet, index=False, header=False)\n",
        "\n",
        "print(f\"NasNetLarge results saved to {path_inception}\")\n",
        "print(f\"InceptionResNetV2 results saved to {path_inception}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "NasNetLarge results saved to predicted_results_inception.csv\nInceptionResNetV2 results saved to predicted_results_inception.csv\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713578473205
        },
        "id": "Lz9XPjg1kYgU",
        "outputId": "39740376-cf52-407b-8021-a81b704e2947"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "ws = Workspace.from_config()  # Or use .get() with explicit parameters\n",
        "compute_target = ws.compute_targets['akrishn21']\n",
        "compute_target.stop(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713570312031
        },
        "id": "B-nza8bVkYgU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "zn9WADeNkYgU"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "myenv",
      "language": "python",
      "display_name": "myenv"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "myenv"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}